{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5245c2e5",
   "metadata": {},
   "source": [
    "Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9f710dd5-5cf6-4272-a7f5-509f50a59840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import intervaltree\n",
    "from intervaltree import Interval, IntervalTree \n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e6ad0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install intervaltree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f511879",
   "metadata": {},
   "source": [
    "The below code takes a genome then splits the genome into intervals called segments. The duplication features of each segment is pooled together to form the features of a segment, this would be called a segmental duplication. We first create intervals of length 1MB, find out which duplicated regiosn overlap with it and then pool all the features to form a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "261a3b0b-c59d-4a1f-be03-e72e361a3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_smallest_region(genome):\n",
    "    smallest=1000000000000000000\n",
    "    for i in genome:\n",
    "        for j in [-1,0,1]:\n",
    "            x=np.abs(list(genome[i])[j].end-list(genome[i])[j+1].begin)\n",
    "            if x<smallest:\n",
    "                smallest=x\n",
    "                print(i)\n",
    "    return smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea82818b-de47-462b-916d-1400a809ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"SD_network/NMF_Analysis/files/telocentro_hg38.bed\"\n",
    "file=open(file_name,\"r\")\n",
    "data=file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6cdab",
   "metadata": {},
   "source": [
    "load the genome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5939c328-f069-470f-8874-c67d45a26b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome={}\n",
    "\n",
    "for i in data:\n",
    "    x=i.split(\"\\t\")\n",
    "    if x[0] not in genome.keys():\n",
    "        genome[x[0]]=IntervalTree()\n",
    "        genome[x[0]][int(x[1]):int(x[2])]=(int(x[1]),int(x[2]))\n",
    "    else:\n",
    "        genome[x[0]][int(x[1]):int(x[2])]=(int(x[1]),int(x[2]))\n",
    "        \n",
    "for key in genome.keys():\n",
    "    genome[key].merge_overlaps(strict=False)\n",
    "\n",
    "del genome[\"chrX\"]\n",
    "del genome[\"chrY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "55c06991-4dfd-41b0-afcb-7c56b601f32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\n",
      "chr2\n",
      "chr3\n",
      "chr4\n",
      "chr5\n",
      "chr8\n",
      "chr10\n",
      "chr12\n",
      "chr13\n",
      "chr14\n",
      "chr18\n",
      "chr21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10890000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_smallest_region(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "647635a4-86ba-4452-b33d-1c92dca3325b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chr1': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(121700000, 125100000), Interval(248946422, 248956422, (248946422, 248956422))]),\n",
       " 'chr2': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(91800000, 96000000), Interval(242183529, 242193529, (242183529, 242193529))]),\n",
       " 'chr3': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(87800000, 94000000), Interval(198285559, 198295559, (198285559, 198295559))]),\n",
       " 'chr4': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(48200000, 51800000), Interval(190204555, 190214555, (190204555, 190214555))]),\n",
       " 'chr5': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(46100000, 51400000), Interval(181528259, 181538259, (181528259, 181538259))]),\n",
       " 'chr6': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(58500000, 62600000), Interval(170795979, 170805979, (170795979, 170805979))]),\n",
       " 'chr7': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(58100000, 62100000), Interval(159335973, 159345973, (159335973, 159345973))]),\n",
       " 'chr8': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(43200000, 47200000), Interval(145128636, 145138636, (145128636, 145138636))]),\n",
       " 'chr9': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(42200000, 45500000), Interval(138384717, 138394717, (138384717, 138394717))]),\n",
       " 'chr10': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(38000000, 41600000), Interval(133787422, 133797422, (133787422, 133797422))]),\n",
       " 'chr11': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(51000000, 55800000), Interval(135076622, 135086622, (135076622, 135086622))]),\n",
       " 'chr12': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(33200000, 37800000), Interval(133265309, 133275309, (133265309, 133275309))]),\n",
       " 'chr13': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(16500000, 18900000), Interval(114354328, 114364328, (114354328, 114364328))]),\n",
       " 'chr14': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(16100000, 18200000), Interval(107033718, 107043718, (107033718, 107043718))]),\n",
       " 'chr15': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(17500000, 20500000), Interval(101981189, 101991189, (101981189, 101991189))]),\n",
       " 'chr16': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(35300000, 38400000), Interval(90328345, 90338345, (90328345, 90338345))]),\n",
       " 'chr17': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(22700000, 27400000), Interval(83247441, 83257441, (83247441, 83257441))]),\n",
       " 'chr18': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(15400000, 21500000), Interval(80363285, 80373285, (80363285, 80373285))]),\n",
       " 'chr19': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(24200000, 28100000), Interval(58607616, 58617616, (58607616, 58617616))]),\n",
       " 'chr20': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(25700000, 30400000), Interval(64434167, 64444167, (64434167, 64444167))]),\n",
       " 'chr21': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(10900000, 13000000), Interval(46699983, 46709983, (46699983, 46709983))]),\n",
       " 'chr22': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(13700000, 17400000), Interval(50808468, 50818468, (50808468, 50818468))])}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "59a83ae0-586a-40c9-b3ff-85aafcaf0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(chromosome_name):\n",
    "    splits = IntervalTree()\n",
    "    x = sorted(genome[chromosome_name])\n",
    "    split_length = 10**6 # 1Mb, depends on the segmental duplication length\n",
    "\n",
    "    for i in range(len(x) - 1):\n",
    "        s = x[i].end\n",
    "        e = x[i + 1].begin\n",
    "\n",
    "        for i in range(s + 1, (s + e) // 2, split_length + 1):\n",
    "            splits[i:i + split_length] = (i, i + split_length)\n",
    "\n",
    "        for i in range(e - 1, (s + e) // 2 + (e - s) % (split_length + 1), -split_length - 1):\n",
    "            splits[i - split_length:i] = (i - split_length, i)\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dea393ac-2e48-4455-9e93-2a2819908279",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=get_splits(\"chr21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "647102c5-17c5-4d2a-b774-8ca245f55d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "67be6b7e-cfee-48a6-9b43-2fc9a04bf981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505239b9",
   "metadata": {},
   "source": [
    "duplicated regions dataset is preprocessed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1b1c535b-184a-48fe-a66a-0c448a5edfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_regions=pd.read_csv(\"SD_network/NMF_Analysis/files/out_df_ws_jumps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4cab7e25-b29b-4475-8b9f-266cf61d5a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chr', 'coor_s', 'coor_e', 'ids', 'length', 'centro', 'telo', 'gaps',\n",
       "       'genes', 'intra_frac', 'cpgisl_in', 'cpgisl_bor', 'ctcf', 'repli_in',\n",
       "       'repli_bor', 'repli_bor_deriv', 'repli_deriv', 'repli_vari',\n",
       "       'recomb_in', 'recomb_bor', 'dnase_in', 'dnase_bor', 'DNA_l', 'LINE_l',\n",
       "       'LTR_l', 'SINE_l', 'Low_complexity_l', 'Retroposon_l', 'Satellite_l',\n",
       "       'Simple_repeat_l', 'rRNA_l', 'snRNA_l', 'scRNA_l', 'srpRNA_l', 'tRNA_l',\n",
       "       'RC_l', 'DNA_r', 'LINE_r', 'LTR_r', 'SINE_r', 'Low_complexity_r',\n",
       "       'Retroposon_r', 'Satellite_r', 'Simple_repeat_r', 'rRNA_r', 'snRNA_r',\n",
       "       'scRNA_r', 'srpRNA_r', 'tRNA_r', 'RC_r', 'L1_s_l', 'L2_s_l', 'MIR_s_l',\n",
       "       'Alu_s_l', 'Satellite_s_l', 'L1_s_r', 'L2_s_r', 'MIR_s_r', 'Alu_s_r',\n",
       "       'Satellite_s_r', 'used_coor_l_s', 'used_coor_l_e', 'used_coor_r_s',\n",
       "       'used_coor_r_e', 'CG_frac_l', 'CG_frac_r', 'CG_frac_in', 'jumps'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_regions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "714a3f16-dada-444a-be45-702c1899e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicated_regions():\n",
    "    add_columns = ['component_size', 'intra_degree', 'iner_degree', 'self_loops', 'edges_double', 'edges_tandem', 'edges_ident_mean']\n",
    "    old_data = pd.read_csv(\"SD_network/NMF_Analysis/files/Duplicated_Regions_old_data.csv\")\n",
    "    duplicated_regions = pd.read_csv(\"SD_network/NMF_Analysis/files/out_df_ws_jumps.csv\")\n",
    "\n",
    "    duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"] == -1.000] = 0.0\n",
    "    duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"] == 0.0] = duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_l\"] == 0.0]\n",
    "    duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"] == -1.000] = 0.0\n",
    "    duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"] == 0.0] = duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_r\"] == 0.0]\n",
    "    duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"] == -1.000] = 0.0\n",
    "    duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"] == 0.0] = np.mean(duplicated_regions[\"CG_frac_in\"])\n",
    "\n",
    "    duplicated_regions[\"CG_frac\"] = (duplicated_regions[\"CG_frac_l\"] + duplicated_regions[\"CG_frac_r\"]) / 2\n",
    "    duplicated_regions[\"CG_frac\"][duplicated_regions[\"CG_frac\"] == 0.0] = np.mean(duplicated_regions[\"CG_frac_in\"])\n",
    "\n",
    "    duplicated_regions.drop([\"CG_frac_l\", \"CG_frac_r\"], axis=1, inplace=True)\n",
    "\n",
    "    for i in add_columns:\n",
    "        duplicated_regions[i] = old_data[i]\n",
    "\n",
    "    left_right_columns = [\"DNA\", \"LINE\", \"LTR\", \"SINE\", \"Low_complexity\", \"Retroposon\", \"Satellite\", \"Simple_repeat\", \"rRNA\", \"snRNA\", \"scRNA\", \"srpRNA\", \"tRNA\", \"RC\", 'L1_s', 'L2_s', 'MIR_s', 'Alu_s', 'Satellite_s']\n",
    "\n",
    "    for i in left_right_columns:\n",
    "        duplicated_regions[i] = duplicated_regions[i + \"_r\"] + duplicated_regions[i + \"_l\"]\n",
    "        duplicated_regions.drop([i + \"_r\", i + \"_l\"], axis=1, inplace=True)\n",
    "\n",
    "    return duplicated_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ed920c8c-9022-4f46-a513-b365f7cea3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicated_regions(splits, duplicated_regions, chromosome_name):\n",
    "    splits2 = copy.deepcopy(splits)\n",
    "    df = duplicated_regions[duplicated_regions[\"chr\"] == chromosome_name]\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        splits2[row[\"coor_s\"]:row[\"coor_e\"]] = row[\"ids\"]\n",
    "\n",
    "    interval_with_duplicated_regions = {}\n",
    "\n",
    "    for i in splits:\n",
    "        overlaps = splits2.overlap(i.begin, i.end)\n",
    "        overlaps.remove(Interval(i.begin, i.end, (i.begin, i.end)))\n",
    "        interval_with_duplicated_regions[(i.begin, i.end)] = overlaps\n",
    "\n",
    "    return interval_with_duplicated_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e20c3bf-2dea-471a-b880-a1369927b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_of_overlap(reg1,reg2):\n",
    "    if reg1[0]<=reg2[0]:\n",
    "        return(reg1[1]-reg2[0])\n",
    "    else:\n",
    "        return(reg2[1]-reg1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "54ac0281-90f8-45ea-9137-2178522d47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(x):\n",
    "    if x>0.933:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d1451b72-967c-45cc-8023-20012e25cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning1(x): #(1.745, 0.196)\n",
    "    if x>0.40174999999999994:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "61c391b3-f3cf-4001-a1f3-a866410d8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning2(x): #0.749, 0.065\n",
    "    if x>0.424:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "93bc463b-f7c6-49b8-bcbb-7129448be14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning_length(x):\n",
    "    if x<2574.5:\n",
    "        return 0 \n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25df1460-e9f2-454c-8410-dce860466ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed=[\"chromosome_name\",\"start\", \"end\",'length_0','length_1', 'jumps',  'gaps', 'genes',\n",
    "       'cpgisl_in', 'cpgisl_bor', 'repli_in', 'repli_bor', 'repli_bor_deriv',\n",
    "       'repli_deriv', 'recomb_in', 'recomb_bor', 'dnase_in', 'dnase_bor','DNA', 'LINE',\n",
    "       'LTR', 'SINE', 'Low_complexity', 'Retroposon', 'Satellite',\n",
    "       'Simple_repeat', 'rRNA', 'snRNA', 'scRNA', 'srpRNA', 'tRNA', 'RC',\n",
    "       'L1_s', 'L2_s', 'MIR_s', 'Alu_s', 'Satellite_s','component_size', 'intra_degree', 'iner_degree', 'self_loops',\n",
    "       'edges_double', 'edges_tandem','edges_ident_mean_0','edges_ident_mean_1',\"CG_frac_0\",\"CG_frac_1\",\"CG_frac_in_0\",\"CG_frac_in_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b0eb6555-2032-4b56-88b7-36686045c6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dc95c182-1782-4e78-8116-603b2b31dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(duplicated_regions):\n",
    "    columns_needed = [\"chromosome_name\", \"start\", \"end\", 'length_0', 'length_1', 'jumps', 'gaps', 'genes',\n",
    "                      'cpgisl_in', 'cpgisl_bor', 'repli_in', 'repli_bor', 'repli_bor_deriv',\n",
    "                      'repli_deriv', 'recomb_in', 'recomb_bor', 'dnase_in', 'dnase_bor', 'DNA', 'LINE',\n",
    "                      'LTR', 'SINE', 'Low_complexity', 'Retroposon', 'Satellite',\n",
    "                      'Simple_repeat', 'rRNA', 'snRNA', 'scRNA', 'srpRNA', 'tRNA', 'RC',\n",
    "                      'L1_s', 'L2_s', 'MIR_s', 'Alu_s', 'Satellite_s', 'component_size', 'intra_degree',\n",
    "                      'iner_degree', 'self_loops', 'edges_double', 'edges_tandem', 'edges_ident_mean_0',\n",
    "                      'edges_ident_mean_1', \"CG_frac_0\", \"CG_frac_1\", \"CG_frac_in_0\", \"CG_frac_in_1\"]\n",
    "\n",
    "    df = pd.DataFrame(columns=columns_needed)\n",
    "\n",
    "    for i in range(1, 23):\n",
    "        print(\"Processing Chromosome:\", i)\n",
    "        chr_name = \"chr\" + str(i)\n",
    "        splits = get_splits(chr_name)\n",
    "        overlap_data = find_duplicated_regions(splits, duplicated_regions, i)\n",
    "\n",
    "        for split in overlap_data:\n",
    "            start = split[0]\n",
    "            end = split[1]\n",
    "            cumm_features = np.zeros(len(columns_needed))\n",
    "            cumm_features[0] = i\n",
    "            cumm_features[1] = start\n",
    "            cumm_features[2] = end\n",
    "\n",
    "            for dups in overlap_data[split]:\n",
    "                dups_id = dups[2]\n",
    "                dup_data = features[features[\"ids\"] == dups_id]\n",
    "\n",
    "                if len(dup_data) != 0:\n",
    "                    length_of_dup = np.array(dup_data[\"length\"])[0]\n",
    "                    cumm_features[3 + binning_length(length_of_dup)] += 1\n",
    "                    index_repli = 5\n",
    "                    for count in np.array(\n",
    "                            dup_data[['jumps', 'gaps', 'genes', 'cpgisl_in', 'cpgisl_bor', 'repli_in',\n",
    "                                       'repli_bor', 'repli_bor_deriv', 'repli_deriv', 'recomb_in',\n",
    "                                       'recomb_bor', 'dnase_in', 'dnase_bor', 'DNA', 'LINE', 'LTR',\n",
    "                                       'SINE', 'Low_complexity', 'Retroposon', 'Satellite', 'Simple_repeat',\n",
    "                                       'rRNA', 'snRNA', 'scRNA', 'srpRNA', 'tRNA', 'RC', 'L1_s', 'L2_s',\n",
    "                                       'MIR_s', 'Alu_s', 'Satellite_s', 'component_size', 'intra_degree',\n",
    "                                       'iner_degree', 'self_loops', 'edges_double', 'edges_tandem',\n",
    "                                       \"CG_frac\", \"CG_frac_in\"]])[0]:\n",
    "                        cumm_features[index_repli] += int(count)\n",
    "                        index_repli += 1\n",
    "                    index_edges_ident_mean = 43\n",
    "                    cumm_features[\n",
    "                        index_edges_ident_mean + int(binning(np.array(dup_data['edges_ident_mean'])[0]))] += 1\n",
    "                    index_cg_frac = 45\n",
    "                    cumm_features[index_cg_frac + int(binning1(np.array(dup_data['CG_frac'])[0]))] += 1\n",
    "                    index_cg_frac_in = 47\n",
    "                    cumm_features[index_cg_frac_in + int(binning2(np.array(dup_data['CG_frac_in'])[0]))] += 1\n",
    "\n",
    "            df2 = pd.DataFrame([cumm_features], columns=columns_needed)\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dcd87fdc-ae81-4a0e-97c1-bd967725bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_89864/2192996762.py:6: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"] == -1.000] = 0.0\n",
      "/scratch/local/ipykernel_89864/2192996762.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"] == -1.000] = 0.0\n",
      "/scratch/local/ipykernel_89864/2192996762.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"] == 0.0] = duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_l\"] == 0.0]\n",
      "/scratch/local/ipykernel_89864/2192996762.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"] == 0.0] = duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_l\"] == 0.0]\n",
      "/scratch/local/ipykernel_89864/2192996762.py:8: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"] == -1.000] = 0.0\n",
      "/scratch/local/ipykernel_89864/2192996762.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"] == -1.000] = 0.0\n",
      "/scratch/local/ipykernel_89864/2192996762.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"] == 0.0] = duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_r\"] == 0.0]\n",
      "/scratch/local/ipykernel_89864/2192996762.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"] == 0.0] = duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_r\"] == 0.0]\n",
      "/scratch/local/ipykernel_89864/2192996762.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"] == -1.000] = 0.0\n",
      "/scratch/local/ipykernel_89864/2192996762.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"] == -1.000] = 0.0\n",
      "/scratch/local/ipykernel_89864/2192996762.py:11: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"] == 0.0] = np.mean(duplicated_regions[\"CG_frac_in\"])\n",
      "/scratch/local/ipykernel_89864/2192996762.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"] == 0.0] = np.mean(duplicated_regions[\"CG_frac_in\"])\n",
      "/scratch/local/ipykernel_89864/2192996762.py:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac\"][duplicated_regions[\"CG_frac\"] == 0.0] = np.mean(duplicated_regions[\"CG_frac_in\"])\n",
      "/scratch/local/ipykernel_89864/2192996762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac\"][duplicated_regions[\"CG_frac\"] == 0.0] = np.mean(duplicated_regions[\"CG_frac_in\"])\n"
     ]
    }
   ],
   "source": [
    "features=get_duplicated_regions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1fb8f8e1-90d1-4fd5-ac42-a78e2533d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(\"SD_network/NMF_Analysis/outputs/1MB/Duplicated_Regions_1MB_processed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5d42f36e-ef71-41ed-bd44-900b3399eac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chromosome: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_89864/3765859507.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, df2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chromosome: 2\n",
      "Processing Chromosome: 3\n",
      "Processing Chromosome: 4\n",
      "Processing Chromosome: 5\n",
      "Processing Chromosome: 6\n",
      "Processing Chromosome: 7\n",
      "Processing Chromosome: 8\n",
      "Processing Chromosome: 9\n",
      "Processing Chromosome: 10\n",
      "Processing Chromosome: 11\n",
      "Processing Chromosome: 12\n",
      "Processing Chromosome: 13\n",
      "Processing Chromosome: 14\n",
      "Processing Chromosome: 15\n",
      "Processing Chromosome: 16\n",
      "Processing Chromosome: 17\n",
      "Processing Chromosome: 18\n",
      "Processing Chromosome: 19\n",
      "Processing Chromosome: 20\n",
      "Processing Chromosome: 21\n",
      "Processing Chromosome: 22\n"
     ]
    }
   ],
   "source": [
    "df_ML_output=create_training_data(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "43a11d2d-c6b7-4cea-a903-b32694a4f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chromosome_name</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>length_0</th>\n",
       "      <th>length_1</th>\n",
       "      <th>jumps</th>\n",
       "      <th>gaps</th>\n",
       "      <th>genes</th>\n",
       "      <th>cpgisl_in</th>\n",
       "      <th>cpgisl_bor</th>\n",
       "      <th>...</th>\n",
       "      <th>iner_degree</th>\n",
       "      <th>self_loops</th>\n",
       "      <th>edges_double</th>\n",
       "      <th>edges_tandem</th>\n",
       "      <th>edges_ident_mean_0</th>\n",
       "      <th>edges_ident_mean_1</th>\n",
       "      <th>CG_frac_0</th>\n",
       "      <th>CG_frac_1</th>\n",
       "      <th>CG_frac_in_0</th>\n",
       "      <th>CG_frac_in_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>187946361.0</td>\n",
       "      <td>188946361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>186946360.0</td>\n",
       "      <td>187946360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27010028.0</td>\n",
       "      <td>28010028.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32010033.0</td>\n",
       "      <td>33010033.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>247946421.0</td>\n",
       "      <td>248946421.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>11699998.0</td>\n",
       "      <td>12699998.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>9699996.0</td>\n",
       "      <td>10699996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>12699999.0</td>\n",
       "      <td>13699999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>10699997.0</td>\n",
       "      <td>11699997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>35808453.0</td>\n",
       "      <td>36808453.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2810 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    chromosome_name        start          end  length_0  length_1  jumps  \\\n",
       "0               1.0  187946361.0  188946361.0       0.0       0.0    0.0   \n",
       "0               1.0  186946360.0  187946360.0       1.0       1.0    2.0   \n",
       "0               1.0   27010028.0   28010028.0       3.0       1.0    6.0   \n",
       "0               1.0   32010033.0   33010033.0       3.0       1.0    4.0   \n",
       "0               1.0  247946421.0  248946421.0       4.0       9.0   17.0   \n",
       "..              ...          ...          ...       ...       ...    ...   \n",
       "0              22.0   11699998.0   12699998.0       1.0       6.0   15.0   \n",
       "0              22.0    9699996.0   10699996.0       0.0       1.0    2.0   \n",
       "0              22.0   12699999.0   13699999.0       0.0       3.0    6.0   \n",
       "0              22.0   10699997.0   11699997.0       0.0      10.0   17.0   \n",
       "0              22.0   35808453.0   36808453.0       1.0       1.0    2.0   \n",
       "\n",
       "    gaps  genes  cpgisl_in  cpgisl_bor  ...  iner_degree  self_loops  \\\n",
       "0    0.0    0.0        0.0         0.0  ...          0.0         0.0   \n",
       "0    0.0    0.0        0.0         0.0  ...          0.0         0.0   \n",
       "0    0.0    4.0        0.0         0.0  ...          3.0         0.0   \n",
       "0    0.0    4.0        0.0         0.0  ...          4.0         0.0   \n",
       "0    1.0   14.0        0.0         0.0  ...         13.0         0.0   \n",
       "..   ...    ...        ...         ...  ...          ...         ...   \n",
       "0    9.0    1.0        6.0         1.0  ...         23.0         3.0   \n",
       "0    1.0    0.0        3.0         1.0  ...          8.0         2.0   \n",
       "0    5.0    0.0        1.0         1.0  ...          0.0         0.0   \n",
       "0   13.0    1.0       13.0         0.0  ...         33.0         0.0   \n",
       "0    0.0    0.0        0.0         0.0  ...          0.0         0.0   \n",
       "\n",
       "    edges_double  edges_tandem  edges_ident_mean_0  edges_ident_mean_1  \\\n",
       "0            0.0           0.0                 0.0                 0.0   \n",
       "0            0.0           0.0                 2.0                 0.0   \n",
       "0            0.0           0.0                 2.0                 2.0   \n",
       "0            0.0           0.0                 2.0                 2.0   \n",
       "0            4.0          14.0                 9.0                 4.0   \n",
       "..           ...           ...                 ...                 ...   \n",
       "0          140.0          10.0                 1.0                 6.0   \n",
       "0           97.0           0.0                 0.0                 1.0   \n",
       "0            5.0           2.0                 0.0                 3.0   \n",
       "0           40.0           5.0                 2.0                 8.0   \n",
       "0            0.0           0.0                 1.0                 1.0   \n",
       "\n",
       "    CG_frac_0  CG_frac_1  CG_frac_in_0  CG_frac_in_1  \n",
       "0         0.0        0.0           0.0           0.0  \n",
       "0         0.0        2.0           1.0           1.0  \n",
       "0         2.0        2.0           1.0           3.0  \n",
       "0         2.0        2.0           2.0           2.0  \n",
       "0        11.0        2.0          11.0           2.0  \n",
       "..        ...        ...           ...           ...  \n",
       "0         1.0        6.0           5.0           2.0  \n",
       "0         0.0        1.0           1.0           0.0  \n",
       "0         0.0        3.0           2.0           1.0  \n",
       "0         2.0        8.0           6.0           4.0  \n",
       "0         1.0        1.0           0.0           2.0  \n",
       "\n",
       "[2810 rows x 49 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ML_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d5071f4b-87e3-4719-ae06-189c8ef1d166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chromosome_name', 'start', 'end', 'length_0', 'length_1', 'jumps',\n",
       "       'gaps', 'genes', 'cpgisl_in', 'cpgisl_bor', 'repli_in', 'repli_bor',\n",
       "       'repli_bor_deriv', 'repli_deriv', 'recomb_in', 'recomb_bor', 'dnase_in',\n",
       "       'dnase_bor', 'DNA', 'LINE', 'LTR', 'SINE', 'Low_complexity',\n",
       "       'Retroposon', 'Satellite', 'Simple_repeat', 'rRNA', 'snRNA', 'scRNA',\n",
       "       'srpRNA', 'tRNA', 'RC', 'L1_s', 'L2_s', 'MIR_s', 'Alu_s', 'Satellite_s',\n",
       "       'component_size', 'intra_degree', 'iner_degree', 'self_loops',\n",
       "       'edges_double', 'edges_tandem', 'edges_ident_mean_0',\n",
       "       'edges_ident_mean_1', 'CG_frac_0', 'CG_frac_1', 'CG_frac_in_0',\n",
       "       'CG_frac_in_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ML_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "476ccadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "0    0.0\n",
       "0    1.0\n",
       "0    0.0\n",
       "0    0.0\n",
       "    ... \n",
       "0    0.0\n",
       "0    0.0\n",
       "0    0.0\n",
       "0    0.0\n",
       "0    1.0\n",
       "Name: DNA, Length: 2810, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ML_output.DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f018cfb7-c448-4c32-87f4-bb8e22dbdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_output.to_csv(\"SD_network/NMF_Analysis/outputs/1MB/Duplicated_Regions_Final_1MB.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
