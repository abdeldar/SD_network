{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f710dd5-5cf6-4272-a7f5-509f50a59840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the csv module to work with csv files\n",
    "import csv \n",
    "\n",
    "# Importing intervaltree and its Interval, IntervalTree classes for efficient interval operations\n",
    "import intervaltree\n",
    "from intervaltree import Interval, IntervalTree \n",
    "\n",
    "# Importing pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Importing copy for creating copies of mutable objects\n",
    "import copy\n",
    "\n",
    "# Importing numpy for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Importing matplotlib's pyplot for data visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ad0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install intervaltree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261a3b0b-c59d-4a1f-be03-e72e361a3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_smallest_region(genome):\n",
    "    # Initialize smallest with a very large number\n",
    "    smallest=1000000000000000000\n",
    "\n",
    "    # Iterate over each item in the genome\n",
    "    for i in genome:\n",
    "        # Iterate over the list [-1, 0, 1]\n",
    "        for j in [-1,0,1]:\n",
    "            # Calculate the absolute difference between the end of the current interval and the beginning of the next interval\n",
    "            x=np.abs(list(genome[i])[j].end-list(genome[i])[j+1].begin)\n",
    "\n",
    "            # If the calculated difference is smaller than the current smallest, update smallest\n",
    "            if x<smallest:\n",
    "                smallest=x\n",
    "                # Print the index of the smallest region\n",
    "                print(i)\n",
    "    # Return the smallest region\n",
    "    return smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea82818b-de47-462b-916d-1400a809ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file name\n",
    "file_name=\"files/telocentro_hg38.bed\"\n",
    "\n",
    "# Open the file in read mode\n",
    "file=open(file_name,\"r\")\n",
    "\n",
    "# Read all the lines from the file and store them in the data variable\n",
    "data=file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5939c328-f069-470f-8874-c67d45a26b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the genome data\n",
    "genome={}\n",
    "\n",
    "# Iterate over each line in the data\n",
    "for i in data:\n",
    "    # Split the line by tab character to get the individual fields\n",
    "    x=i.split(\"\\t\")\n",
    "\n",
    "    # If the first field (x[0]) is not already a key in the genome dictionary\n",
    "    if x[0] not in genome.keys():\n",
    "        # Create a new IntervalTree for this key\n",
    "        genome[x[0]]=IntervalTree()\n",
    "\n",
    "        # Add a new interval to the IntervalTree with the second and third fields as the start and end of the interval\n",
    "        # The value of the interval is a tuple of the start and end\n",
    "        genome[x[0]][int(x[1]):int(x[2])]=(int(x[1]),int(x[2]))\n",
    "\n",
    "    # If the first field (x[0]) is already a key in the genome dictionary\n",
    "    else:\n",
    "        # Add a new interval to the existing IntervalTree with the second and third fields as the start and end of the interval\n",
    "        # The value of the interval is a tuple of the start and end\n",
    "        genome[x[0]][int(x[1]):int(x[2])]=(int(x[1]),int(x[2]))\n",
    "        \n",
    "# Iterate over each key in the genome dictionary\n",
    "for key in genome.keys():\n",
    "    # Merge overlapping intervals in the IntervalTree for this key\n",
    "    # The strict parameter is set to False, which means that adjacent intervals will be merged\n",
    "    genome[key].merge_overlaps(strict=False)\n",
    "\n",
    "# Delete the key \"chrX\" from the genome dictionary\n",
    "del genome[\"chrX\"]\n",
    "\n",
    "# Delete the key \"chrY\" from the genome dictionary\n",
    "del genome[\"chrY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c06991-4dfd-41b0-afcb-7c56b601f32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\n",
      "chr2\n",
      "chr3\n",
      "chr4\n",
      "chr5\n",
      "chr8\n",
      "chr10\n",
      "chr12\n",
      "chr13\n",
      "chr14\n",
      "chr18\n",
      "chr21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10890000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_smallest_region(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "647635a4-86ba-4452-b33d-1c92dca3325b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chr1': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(121700000, 125100000), Interval(248946422, 248956422, (248946422, 248956422))]),\n",
       " 'chr2': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(91800000, 96000000), Interval(242183529, 242193529, (242183529, 242193529))]),\n",
       " 'chr3': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(87800000, 94000000), Interval(198285559, 198295559, (198285559, 198295559))]),\n",
       " 'chr4': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(48200000, 51800000), Interval(190204555, 190214555, (190204555, 190214555))]),\n",
       " 'chr5': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(46100000, 51400000), Interval(181528259, 181538259, (181528259, 181538259))]),\n",
       " 'chr6': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(58500000, 62600000), Interval(170795979, 170805979, (170795979, 170805979))]),\n",
       " 'chr7': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(58100000, 62100000), Interval(159335973, 159345973, (159335973, 159345973))]),\n",
       " 'chr8': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(43200000, 47200000), Interval(145128636, 145138636, (145128636, 145138636))]),\n",
       " 'chr9': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(42200000, 45500000), Interval(138384717, 138394717, (138384717, 138394717))]),\n",
       " 'chr10': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(38000000, 41600000), Interval(133787422, 133797422, (133787422, 133797422))]),\n",
       " 'chr11': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(51000000, 55800000), Interval(135076622, 135086622, (135076622, 135086622))]),\n",
       " 'chr12': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(33200000, 37800000), Interval(133265309, 133275309, (133265309, 133275309))]),\n",
       " 'chr13': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(16500000, 18900000), Interval(114354328, 114364328, (114354328, 114364328))]),\n",
       " 'chr14': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(16100000, 18200000), Interval(107033718, 107043718, (107033718, 107043718))]),\n",
       " 'chr15': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(17500000, 20500000), Interval(101981189, 101991189, (101981189, 101991189))]),\n",
       " 'chr16': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(35300000, 38400000), Interval(90328345, 90338345, (90328345, 90338345))]),\n",
       " 'chr17': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(22700000, 27400000), Interval(83247441, 83257441, (83247441, 83257441))]),\n",
       " 'chr18': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(15400000, 21500000), Interval(80363285, 80373285, (80363285, 80373285))]),\n",
       " 'chr19': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(24200000, 28100000), Interval(58607616, 58617616, (58607616, 58617616))]),\n",
       " 'chr20': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(25700000, 30400000), Interval(64434167, 64444167, (64434167, 64444167))]),\n",
       " 'chr21': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(10900000, 13000000), Interval(46699983, 46709983, (46699983, 46709983))]),\n",
       " 'chr22': IntervalTree([Interval(0, 10000, (0, 10000)), Interval(13700000, 17400000), Interval(50808468, 50818468, (50808468, 50818468))])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a83ae0-586a-40c9-b3ff-85aafcaf0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the genome into smaller regions\n",
    "def get_splits(chromosome_name):\n",
    "    # Initialize an IntervalTree to store the splits\n",
    "    splits=IntervalTree()\n",
    "\n",
    "    # Get the sorted list of intervals for the given chromosome\n",
    "    x=sorted(genome[chromosome_name])\n",
    "    print(len(x))\n",
    "\n",
    "    # Define the length of each split\n",
    "    split_length=(10**7)\n",
    "\n",
    "    # Iterate over each interval in the list (except the last one)\n",
    "    for i in range(len(x)-1):\n",
    "        # Get the end of the current interval and the beginning of the next interval\n",
    "        s=x[i].end\n",
    "        e=x[i+1].begin\n",
    "\n",
    "        # Create splits from the end of the current interval to the middle of the gap between the current and next interval\n",
    "        for i in range(s+1,(s+e)//2,split_length+1):\n",
    "            splits[i:i+split_length]=(i,i+split_length)\n",
    "\n",
    "        # Create splits from the beginning of the next interval to the middle of the gap between the current and next interval\n",
    "        for i in range( e-1 , (s+e)//2 + (e-s)%(split_length+1) , -split_length-1): #  -split_length-1 \n",
    "            splits[i-split_length:i]=(i-split_length,i)\n",
    "\n",
    "    # Return the IntervalTree of splits\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea393ac-2e48-4455-9e93-2a2819908279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "splits=get_splits(\"chr21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "647102c5-17c5-4d2a-b774-8ca245f55d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67be6b7e-cfee-48a6-9b43-2fc9a04bf981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b1c535b-184a-48fe-a66a-0c448a5edfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_regions=pd.read_csv(\"files/out_df_ws_jumps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cab7e25-b29b-4475-8b9f-266cf61d5a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>coor_s</th>\n",
       "      <th>coor_e</th>\n",
       "      <th>ids</th>\n",
       "      <th>jumps</th>\n",
       "      <th>length</th>\n",
       "      <th>centro</th>\n",
       "      <th>telo</th>\n",
       "      <th>gaps</th>\n",
       "      <th>genes</th>\n",
       "      <th>...</th>\n",
       "      <th>MIR_s_r</th>\n",
       "      <th>Alu_s_r</th>\n",
       "      <th>Satellite_s_r</th>\n",
       "      <th>used_coor_l_s</th>\n",
       "      <th>used_coor_l_e</th>\n",
       "      <th>used_coor_r_s</th>\n",
       "      <th>used_coor_r_e</th>\n",
       "      <th>CG_frac_l</th>\n",
       "      <th>CG_frac_r</th>\n",
       "      <th>CG_frac_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>207666</td>\n",
       "      <td>id1</td>\n",
       "      <td>3</td>\n",
       "      <td>197666</td>\n",
       "      <td>121818793</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9950</td>\n",
       "      <td>10000</td>\n",
       "      <td>207666</td>\n",
       "      <td>207716</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>257666</td>\n",
       "      <td>297956</td>\n",
       "      <td>id2</td>\n",
       "      <td>3</td>\n",
       "      <td>40290</td>\n",
       "      <td>121728503</td>\n",
       "      <td>247666</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>257616</td>\n",
       "      <td>257666</td>\n",
       "      <td>297956</td>\n",
       "      <td>298006</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>347968</td>\n",
       "      <td>535988</td>\n",
       "      <td>id3</td>\n",
       "      <td>1</td>\n",
       "      <td>188020</td>\n",
       "      <td>121490471</td>\n",
       "      <td>337968</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347918</td>\n",
       "      <td>347968</td>\n",
       "      <td>535988</td>\n",
       "      <td>536038</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>585988</td>\n",
       "      <td>817292</td>\n",
       "      <td>id4</td>\n",
       "      <td>4</td>\n",
       "      <td>231304</td>\n",
       "      <td>121209167</td>\n",
       "      <td>575988</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>585938</td>\n",
       "      <td>585988</td>\n",
       "      <td>817292</td>\n",
       "      <td>817342</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>817367</td>\n",
       "      <td>821400</td>\n",
       "      <td>id5</td>\n",
       "      <td>1</td>\n",
       "      <td>4033</td>\n",
       "      <td>121205059</td>\n",
       "      <td>807367</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>817317</td>\n",
       "      <td>817367</td>\n",
       "      <td>821400</td>\n",
       "      <td>821450</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6651</th>\n",
       "      <td>22</td>\n",
       "      <td>48911634</td>\n",
       "      <td>48912886</td>\n",
       "      <td>id4359</td>\n",
       "      <td>1</td>\n",
       "      <td>1252</td>\n",
       "      <td>33857316</td>\n",
       "      <td>1895582</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48911584</td>\n",
       "      <td>48911634</td>\n",
       "      <td>48912886</td>\n",
       "      <td>48912936</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6652</th>\n",
       "      <td>22</td>\n",
       "      <td>49383944</td>\n",
       "      <td>49385910</td>\n",
       "      <td>id4360</td>\n",
       "      <td>1</td>\n",
       "      <td>1966</td>\n",
       "      <td>34329626</td>\n",
       "      <td>1422558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49383894</td>\n",
       "      <td>49383944</td>\n",
       "      <td>49385910</td>\n",
       "      <td>49385960</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6653</th>\n",
       "      <td>22</td>\n",
       "      <td>49386637</td>\n",
       "      <td>49388496</td>\n",
       "      <td>id4361</td>\n",
       "      <td>1</td>\n",
       "      <td>1859</td>\n",
       "      <td>34332319</td>\n",
       "      <td>1419972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49386587</td>\n",
       "      <td>49386637</td>\n",
       "      <td>49388496</td>\n",
       "      <td>49388546</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6654</th>\n",
       "      <td>22</td>\n",
       "      <td>50432257</td>\n",
       "      <td>50442552</td>\n",
       "      <td>id4362</td>\n",
       "      <td>2</td>\n",
       "      <td>10295</td>\n",
       "      <td>35377939</td>\n",
       "      <td>365916</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50432207</td>\n",
       "      <td>50432257</td>\n",
       "      <td>50442552</td>\n",
       "      <td>50442602</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>22</td>\n",
       "      <td>50740515</td>\n",
       "      <td>50808468</td>\n",
       "      <td>id4363</td>\n",
       "      <td>2</td>\n",
       "      <td>67953</td>\n",
       "      <td>35686197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50740465</td>\n",
       "      <td>50740515</td>\n",
       "      <td>50808468</td>\n",
       "      <td>50808518</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6656 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chr    coor_s    coor_e     ids  jumps  length     centro     telo  \\\n",
       "0       1     10000    207666     id1      3  197666  121818793        0   \n",
       "1       1    257666    297956     id2      3   40290  121728503   247666   \n",
       "2       1    347968    535988     id3      1  188020  121490471   337968   \n",
       "3       1    585988    817292     id4      4  231304  121209167   575988   \n",
       "4       1    817367    821400     id5      1    4033  121205059   807367   \n",
       "...   ...       ...       ...     ...    ...     ...        ...      ...   \n",
       "6651   22  48911634  48912886  id4359      1    1252   33857316  1895582   \n",
       "6652   22  49383944  49385910  id4360      1    1966   34329626  1422558   \n",
       "6653   22  49386637  49388496  id4361      1    1859   34332319  1419972   \n",
       "6654   22  50432257  50442552  id4362      2   10295   35377939   365916   \n",
       "6655   22  50740515  50808468  id4363      2   67953   35686197        0   \n",
       "\n",
       "      gaps  genes  ...  MIR_s_r  Alu_s_r  Satellite_s_r  used_coor_l_s  \\\n",
       "0        2      6  ...        0        0              0           9950   \n",
       "1        2      0  ...        0        1              0         257616   \n",
       "2        2      1  ...        0        0              0         347918   \n",
       "3        1      2  ...        0        0              0         585938   \n",
       "4        0      1  ...        0        0              0         817317   \n",
       "...    ...    ...  ...      ...      ...            ...            ...   \n",
       "6651     0      0  ...        0        0              0       48911584   \n",
       "6652     0      0  ...        0        0              0       49383894   \n",
       "6653     0      0  ...        0        0              0       49386587   \n",
       "6654     0      1  ...        0        1              0       50432207   \n",
       "6655     1      3  ...        0        0              0       50740465   \n",
       "\n",
       "      used_coor_l_e  used_coor_r_s  used_coor_r_e  CG_frac_l  CG_frac_r  \\\n",
       "0             10000         207666         207716     -1.000      0.000   \n",
       "1            257666         297956         298006     -1.000      0.538   \n",
       "2            347968         535988         536038     -1.000      1.000   \n",
       "3            585988         817292         817342     -1.000      0.412   \n",
       "4            817367         821400         821450      0.392      0.529   \n",
       "...             ...            ...            ...        ...        ...   \n",
       "6651       48911634       48912886       48912936      0.490      0.451   \n",
       "6652       49383944       49385910       49385960      0.510      0.392   \n",
       "6653       49386637       49388496       49388546      0.392      0.314   \n",
       "6654       50432257       50442552       50442602      0.725      0.451   \n",
       "6655       50740515       50808468       50808518      0.569      0.000   \n",
       "\n",
       "      CG_frac_in  \n",
       "0          0.444  \n",
       "1          0.391  \n",
       "2          0.430  \n",
       "3          0.428  \n",
       "4          0.510  \n",
       "...          ...  \n",
       "6651       0.468  \n",
       "6652       0.393  \n",
       "6653       0.397  \n",
       "6654       0.648  \n",
       "6655       0.454  \n",
       "\n",
       "[6656 rows x 68 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "714a3f16-dada-444a-be45-702c1899e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicated_regions():\n",
    "    # Define the columns to be added from the old data\n",
    "    add_columns=['component_size', 'intra_degree', 'iner_degree', 'self_loops', 'edges_double', 'edges_tandem','edges_ident_mean']\n",
    "\n",
    "    # Read the old data and the duplicated regions data from CSV files\n",
    "    old_data=pd.read_csv(\"files/Duplicated_Regions_old_data.csv\")\n",
    "    duplicated_regions=pd.read_csv(\"files/out_df_ws_jumps.csv\")\n",
    "\n",
    "    # Replace -1.000 with 0.0 in the CG_frac_l, CG_frac_r, and CG_frac_in columns\n",
    "    # Replace 0.0 with the corresponding value from the CG_frac_r or CG_frac_l column or the mean of the CG_frac_in column\n",
    "    duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"]==-1.000]=0.0\n",
    "    duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"]==0.0]=duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_l\"]==0.0]\n",
    "    duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"]==-1.000]=0.0\n",
    "    duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"]==0.0]=duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_r\"]==0.0]\n",
    "    duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"]==-1.000]=0.0\n",
    "    duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"]==0.0]=np.mean(duplicated_regions[\"CG_frac_in\"])\n",
    "\n",
    "    # Calculate the mean of the CG_frac_l and CG_frac_r columns and store it in the CG_frac column\n",
    "    duplicated_regions[\"CG_frac\"]=(duplicated_regions[\"CG_frac_l\"]+duplicated_regions[\"CG_frac_r\"])/2\n",
    "\n",
    "    # Replace 0.0 in the CG_frac column with the mean of the CG_frac_in column\n",
    "    duplicated_regions[\"CG_frac\"][duplicated_regions[\"CG_frac\"]==0.0]=np.mean(duplicated_regions[\"CG_frac_in\"])\n",
    "\n",
    "    # Drop the CG_frac_l and CG_frac_r columns\n",
    "    duplicated_regions.drop([\"CG_frac_l\",\"CG_frac_r\"],axis=1,inplace=True)\n",
    "\n",
    "    # Add the columns from the old data to the duplicated regions data\n",
    "    for i in add_columns:\n",
    "        duplicated_regions[i]=old_data[i]\n",
    "\n",
    "    # Define the columns that have a left and right version\n",
    "    left_right_columns=[\"DNA\",\"LINE\",\"LTR\",\"SINE\",\"Low_complexity\",\"Retroposon\",\"Satellite\",\"Simple_repeat\",\"rRNA\",\"snRNA\",\"scRNA\",\"srpRNA\",\"tRNA\",\"RC\", 'L1_s', 'L2_s', 'MIR_s', 'Alu_s', 'Satellite_s']\n",
    "\n",
    "    # Combine the left and right versions of the columns and drop the original columns\n",
    "    for i in left_right_columns:\n",
    "        duplicated_regions[i]=duplicated_regions[i+\"_r\"]+duplicated_regions[i+\"_l\"]\n",
    "        duplicated_regions.drop([i+\"_r\",i+\"_l\"],axis=1,inplace=True)\n",
    "\n",
    "    # Return the processed duplicated regions data\n",
    "    return duplicated_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed920c8c-9022-4f46-a513-b365f7cea3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicated_regions(splits, duplicated_regions, chromosome_name):\n",
    "    # Create a deep copy of the splits IntervalTree\n",
    "    splits2 = copy.deepcopy(splits)\n",
    "\n",
    "    # Filter the duplicated regions DataFrame for the given chromosome\n",
    "    df = duplicated_regions[duplicated_regions[\"chr\"] == chromosome_name]\n",
    "\n",
    "    # For each row in the filtered DataFrame, add an interval to the splits2 IntervalTree\n",
    "    # The interval begins at the start coordinate and ends at the end coordinate of the row\n",
    "    # The data of the interval is the ID of the row\n",
    "    for i, row in df.iterrows():\n",
    "        splits2[row[\"coor_s\"]:row[\"coor_e\"]] = row[\"ids\"]\n",
    "\n",
    "    # Initialize a dictionary to store the intervals in the splits IntervalTree that overlap with the intervals in the splits2 IntervalTree\n",
    "    interval_with_duplicated_regions = {}\n",
    "\n",
    "    # For each interval in the splits IntervalTree, find the overlapping intervals in the splits2 IntervalTree\n",
    "    # Remove the interval itself from the list of overlaps\n",
    "    # Add the list of overlaps to the dictionary with the interval as the key\n",
    "    for i in splits:\n",
    "        overlaps = splits2.overlap(i.begin, i.end)\n",
    "        overlaps.remove(Interval(i.begin, i.end, (i.begin, i.end)))\n",
    "        interval_with_duplicated_regions[(i.begin, i.end)] = overlaps\n",
    "\n",
    "    # Return the dictionary of intervals with overlapping intervals\n",
    "    return interval_with_duplicated_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e20c3bf-2dea-471a-b880-a1369927b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_of_overlap(reg1,reg2):\n",
    "    if reg1[0]<=reg2[0]:\n",
    "        return(reg1[1]-reg2[0])\n",
    "    else:\n",
    "        return(reg2[1]-reg1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54ac0281-90f8-45ea-9137-2178522d47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(x):\n",
    "    if x>0.933:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1451b72-967c-45cc-8023-20012e25cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning1(x): #(1.745, 0.196)\n",
    "    if x>0.40174999999999994:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c391b3-f3cf-4001-a1f3-a866410d8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning2(x): #0.749, 0.065\n",
    "    if x>0.424:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93bc463b-f7c6-49b8-bcbb-7129448be14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning_length(x):\n",
    "    if x<2574.5:\n",
    "        return 0 \n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25df1460-e9f2-454c-8410-dce860466ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed=[\"chromosome_name\",\"start\", \"end\",'length_0','length_1', 'jumps',  'gaps', 'genes',\n",
    "       'cpgisl_in', 'cpgisl_bor', 'repli_in', 'repli_bor', 'repli_bor_deriv',\n",
    "       'repli_deriv', 'recomb_in', 'recomb_bor', 'dnase_in', 'dnase_bor','DNA', 'LINE',\n",
    "       'LTR', 'SINE', 'Low_complexity', 'Retroposon', 'Satellite',\n",
    "       'Simple_repeat', 'rRNA', 'snRNA', 'scRNA', 'srpRNA', 'tRNA', 'RC',\n",
    "       'L1_s', 'L2_s', 'MIR_s', 'Alu_s', 'Satellite_s','component_size', 'intra_degree', 'iner_degree', 'self_loops',\n",
    "       'edges_double', 'edges_tandem','edges_ident_mean_0','edges_ident_mean_1',\"CG_frac_0\",\"CG_frac_1\",\"CG_frac_in_0\",\"CG_frac_in_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0eb6555-2032-4b56-88b7-36686045c6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc95c182-1782-4e78-8116-603b2b31dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(duplicated_regions):\n",
    "    # Define the columns needed for the DataFrame\n",
    "    columns_needed = [\"chromosome_name\", \"start\", \"end\", 'length_0', 'length_1', 'jumps', 'gaps', 'genes',\n",
    "                      'cpgisl_in', 'cpgisl_bor', 'repli_in', 'repli_bor', 'repli_bor_deriv',\n",
    "                      'repli_deriv', 'recomb_in', 'recomb_bor', 'dnase_in', 'dnase_bor', 'DNA', 'LINE',\n",
    "                      'LTR', 'SINE', 'Low_complexity', 'Retroposon', 'Satellite',\n",
    "                      'Simple_repeat', 'rRNA', 'snRNA', 'scRNA', 'srpRNA', 'tRNA', 'RC',\n",
    "                      'L1_s', 'L2_s', 'MIR_s', 'Alu_s', 'Satellite_s', 'component_size', 'intra_degree',\n",
    "                      'iner_degree', 'self_loops', 'edges_double', 'edges_tandem', 'edges_ident_mean_0',\n",
    "                      'edges_ident_mean_1', \"CG_frac_0\", \"CG_frac_1\", \"CG_frac_in_0\", \"CG_frac_in_1\"]\n",
    "\n",
    "    df = pd.DataFrame(columns=columns_needed)  # Initialize an empty DataFrame to store the training data\n",
    "\n",
    "    for i in range(1, 23):  # Iterate over chromosome numbers (1 to 22)\n",
    "        print(\"Processing Chromosome:\", i)\n",
    "        chr_name = \"chr\" + str(i)  # Construct the chromosome name\n",
    "        splits = get_splits(chr_name)  # Get the split points for the chromosome\n",
    "        overlap_data = find_duplicated_regions(splits, duplicated_regions, i)  # Find duplicated regions for the chromosome\n",
    "\n",
    "        for split in overlap_data:  # Iterate over each split\n",
    "            start = split[0]  # Start position of the split\n",
    "            end = split[1]  # End position of the split\n",
    "            cumm_features = np.zeros(len(columns_needed))  # Initialize an array for cumulative features\n",
    "            # Store the chromosome name, start, and end positions of the split in the cumulative features array\n",
    "            cumm_features[0] = i\n",
    "            cumm_features[1] = start\n",
    "            cumm_features[2] = end\n",
    "\n",
    "            for dups in overlap_data[split]:  # Iterate over duplicated regions within the split\n",
    "\n",
    "                # Extract relevant row from feature data (duplication region).\n",
    "                dups_id = dups[2]\n",
    "                dup_data = features[features[\"ids\"] == dups_id]\n",
    "\n",
    "                # Extracting overlap length ratio\n",
    "                if len(dup_data) != 0:\n",
    "                    length_of_dup = np.array(dup_data[\"length\"])[0]\n",
    "                    cumm_features[3 + binning_length(length_of_dup)] += 1\n",
    "                    # Add features related to replication, recombination, and DNase\n",
    "                    index_repli = 5\n",
    "                    for count in np.array(\n",
    "                            dup_data[['jumps', 'gaps', 'genes', 'cpgisl_in', 'cpgisl_bor', 'repli_in',\n",
    "                                       'repli_bor', 'repli_bor_deriv', 'repli_deriv', 'recomb_in',\n",
    "                                       'recomb_bor', 'dnase_in', 'dnase_bor', 'DNA', 'LINE', 'LTR',\n",
    "                                       'SINE', 'Low_complexity', 'Retroposon', 'Satellite', 'Simple_repeat',\n",
    "                                       'rRNA', 'snRNA', 'scRNA', 'srpRNA', 'tRNA', 'RC', 'L1_s', 'L2_s',\n",
    "                                       'MIR_s', 'Alu_s', 'Satellite_s', 'component_size', 'intra_degree',\n",
    "                                       'iner_degree', 'self_loops', 'edges_double', 'edges_tandem',\n",
    "                                       \"CG_frac\", \"CG_frac_in\"]])[0]:\n",
    "                        cumm_features[index_repli] += int(count)\n",
    "                        index_repli += 1\n",
    "                    # Add features related to edges identification mean\n",
    "                    index_edges_ident_mean = 43\n",
    "                    cumm_features[\n",
    "                        index_edges_ident_mean + int(binning(np.array(dup_data['edges_ident_mean'])[0]))] += 1\n",
    "\n",
    "                    # Add features related to CG fraction\n",
    "                    index_cg_frac = 45\n",
    "                    cumm_features[index_cg_frac + int(binning1(np.array(dup_data['CG_frac'])[0]))] += 1\n",
    "\n",
    "                    # Add features related to CG fraction in\n",
    "                    index_cg_frac_in = 47\n",
    "                    cumm_features[index_cg_frac_in + int(binning2(np.array(dup_data['CG_frac_in'])[0]))] += 1\n",
    "\n",
    "            # Add the row data into DataFrame\n",
    "            df2 = pd.DataFrame([cumm_features], columns=columns_needed)\n",
    "            df = pd.concat([df, df2])  # Concatenate the DataFrame with the new row\n",
    "\n",
    "    return df  # Return the DataFrame containing the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcd87fdc-ae81-4a0e-97c1-bd967725bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34207/3842241318.py:11: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"]==-1.000]=0.0\n",
      "/tmp/ipykernel_34207/3842241318.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"]==-1.000]=0.0\n",
      "/tmp/ipykernel_34207/3842241318.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"]==0.0]=duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_l\"]==0.0]\n",
      "/tmp/ipykernel_34207/3842241318.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_l\"]==0.0]=duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_l\"]==0.0]\n",
      "/tmp/ipykernel_34207/3842241318.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"]==-1.000]=0.0\n",
      "/tmp/ipykernel_34207/3842241318.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"]==-1.000]=0.0\n",
      "/tmp/ipykernel_34207/3842241318.py:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"]==0.0]=duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_r\"]==0.0]\n",
      "/tmp/ipykernel_34207/3842241318.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_r\"][duplicated_regions[\"CG_frac_r\"]==0.0]=duplicated_regions[\"CG_frac_l\"][duplicated_regions[\"CG_frac_r\"]==0.0]\n",
      "/tmp/ipykernel_34207/3842241318.py:15: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"]==-1.000]=0.0\n",
      "/tmp/ipykernel_34207/3842241318.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"]==-1.000]=0.0\n",
      "/tmp/ipykernel_34207/3842241318.py:16: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"]==0.0]=np.mean(duplicated_regions[\"CG_frac_in\"])\n",
      "/tmp/ipykernel_34207/3842241318.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac_in\"][duplicated_regions[\"CG_frac_in\"]==0.0]=np.mean(duplicated_regions[\"CG_frac_in\"])\n",
      "/tmp/ipykernel_34207/3842241318.py:22: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  duplicated_regions[\"CG_frac\"][duplicated_regions[\"CG_frac\"]==0.0]=np.mean(duplicated_regions[\"CG_frac_in\"])\n",
      "/tmp/ipykernel_34207/3842241318.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicated_regions[\"CG_frac\"][duplicated_regions[\"CG_frac\"]==0.0]=np.mean(duplicated_regions[\"CG_frac_in\"])\n"
     ]
    }
   ],
   "source": [
    "features=get_duplicated_regions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fb8f8e1-90d1-4fd5-ac42-a78e2533d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(\"files/Duplicated_Regions_6.6k.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d42f36e-ef71-41ed-bd44-900b3399eac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chromosome: 1\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34207/1885382976.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, df2])  # Concatenate the DataFrame with the new row\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chromosome: 2\n",
      "3\n",
      "Processing Chromosome: 3\n",
      "3\n",
      "Processing Chromosome: 4\n",
      "3\n",
      "Processing Chromosome: 5\n",
      "3\n",
      "Processing Chromosome: 6\n",
      "3\n",
      "Processing Chromosome: 7\n",
      "3\n",
      "Processing Chromosome: 8\n",
      "3\n",
      "Processing Chromosome: 9\n",
      "3\n",
      "Processing Chromosome: 10\n",
      "3\n",
      "Processing Chromosome: 11\n",
      "3\n",
      "Processing Chromosome: 12\n",
      "3\n",
      "Processing Chromosome: 13\n",
      "3\n",
      "Processing Chromosome: 14\n",
      "3\n",
      "Processing Chromosome: 15\n",
      "3\n",
      "Processing Chromosome: 16\n",
      "3\n",
      "Processing Chromosome: 17\n",
      "3\n",
      "Processing Chromosome: 18\n",
      "3\n",
      "Processing Chromosome: 19\n",
      "3\n",
      "Processing Chromosome: 20\n",
      "3\n",
      "Processing Chromosome: 21\n",
      "3\n",
      "Processing Chromosome: 22\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "df_ML_output=create_training_data(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43a11d2d-c6b7-4cea-a903-b32694a4f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chromosome_name</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>length_0</th>\n",
       "      <th>length_1</th>\n",
       "      <th>jumps</th>\n",
       "      <th>gaps</th>\n",
       "      <th>genes</th>\n",
       "      <th>cpgisl_in</th>\n",
       "      <th>cpgisl_bor</th>\n",
       "      <th>...</th>\n",
       "      <th>iner_degree</th>\n",
       "      <th>self_loops</th>\n",
       "      <th>edges_double</th>\n",
       "      <th>edges_tandem</th>\n",
       "      <th>edges_ident_mean_0</th>\n",
       "      <th>edges_ident_mean_1</th>\n",
       "      <th>CG_frac_0</th>\n",
       "      <th>CG_frac_1</th>\n",
       "      <th>CG_frac_in_0</th>\n",
       "      <th>CG_frac_in_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>10010001.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>218946419.0</td>\n",
       "      <td>228946419.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>165100005.0</td>\n",
       "      <td>175100005.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>125100001.0</td>\n",
       "      <td>135100001.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30010004.0</td>\n",
       "      <td>40010004.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>10010001.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>17400001.0</td>\n",
       "      <td>27400001.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>27400002.0</td>\n",
       "      <td>37400002.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>40808467.0</td>\n",
       "      <td>50808467.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>30808466.0</td>\n",
       "      <td>40808466.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    chromosome_name        start          end  length_0  length_1  jumps  \\\n",
       "0               1.0      10001.0   10010001.0       7.0      29.0   51.0   \n",
       "0               1.0  218946419.0  228946419.0      13.0      15.0   36.0   \n",
       "0               1.0  165100005.0  175100005.0      14.0       6.0   24.0   \n",
       "0               1.0  125100001.0  135100001.0       0.0       4.0    9.0   \n",
       "0               1.0   30010004.0   40010004.0      25.0       8.0   35.0   \n",
       "..              ...          ...          ...       ...       ...    ...   \n",
       "0              22.0      10001.0   10010001.0       0.0       0.0    0.0   \n",
       "0              22.0   17400001.0   27400001.0      23.0      86.0  166.0   \n",
       "0              22.0   27400002.0   37400002.0      13.0      19.0   39.0   \n",
       "0              22.0   40808467.0   50808467.0      24.0      17.0   51.0   \n",
       "0              22.0   30808466.0   40808466.0       9.0      19.0   36.0   \n",
       "\n",
       "    gaps  genes  cpgisl_in  cpgisl_bor  ...  iner_degree  self_loops  \\\n",
       "0    9.0   40.0       44.0         2.0  ...        140.0        11.0   \n",
       "0    2.0   15.0       44.0         2.0  ...         30.0         2.0   \n",
       "0    0.0   15.0        1.0         0.0  ...         24.0         0.0   \n",
       "0    4.0    0.0        2.0         1.0  ...         62.0         3.0   \n",
       "0    0.0   23.0        7.0         2.0  ...         39.0         0.0   \n",
       "..   ...    ...        ...         ...  ...          ...         ...   \n",
       "0    0.0    0.0        0.0         0.0  ...          0.0         0.0   \n",
       "0    6.0  107.0       69.0         4.0  ...         77.0        10.0   \n",
       "0    0.0   25.0        3.0         1.0  ...          7.0         2.0   \n",
       "0    1.0   34.0       12.0         1.0  ...         19.0         0.0   \n",
       "0    0.0   26.0        4.0         2.0  ...         15.0         3.0   \n",
       "\n",
       "    edges_double  edges_tandem  edges_ident_mean_0  edges_ident_mean_1  \\\n",
       "0          184.0          28.0                13.0                24.0   \n",
       "0           96.0          10.0                17.0                11.0   \n",
       "0            0.0           2.0                12.0                 8.0   \n",
       "0          101.0           2.0                 2.0                 2.0   \n",
       "0            0.0           9.0                16.0                17.0   \n",
       "..           ...           ...                 ...                 ...   \n",
       "0            0.0           0.0                 0.0                 0.0   \n",
       "0          255.0          80.0                38.0                71.0   \n",
       "0            2.0           4.0                14.0                18.0   \n",
       "0            8.0          24.0                19.0                22.0   \n",
       "0            4.0           8.0                12.0                16.0   \n",
       "\n",
       "    CG_frac_0  CG_frac_1  CG_frac_in_0  CG_frac_in_1  \n",
       "0         5.0       31.0           6.0          30.0  \n",
       "0        13.0       15.0          13.0          15.0  \n",
       "0        16.0        4.0          14.0           6.0  \n",
       "0         1.0        3.0           4.0           0.0  \n",
       "0        11.0       22.0           8.0          25.0  \n",
       "..        ...        ...           ...           ...  \n",
       "0         0.0        0.0           0.0           0.0  \n",
       "0        25.0       84.0          25.0          84.0  \n",
       "0         7.0       25.0          11.0          21.0  \n",
       "0        11.0       30.0           6.0          35.0  \n",
       "0         5.0       23.0           9.0          19.0  \n",
       "\n",
       "[301 rows x 49 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ML_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5071f4b-87e3-4719-ae06-189c8ef1d166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chromosome_name', 'start', 'end', 'length_0', 'length_1', 'jumps',\n",
       "       'gaps', 'genes', 'cpgisl_in', 'cpgisl_bor', 'repli_in', 'repli_bor',\n",
       "       'repli_bor_deriv', 'repli_deriv', 'recomb_in', 'recomb_bor', 'dnase_in',\n",
       "       'dnase_bor', 'DNA', 'LINE', 'LTR', 'SINE', 'Low_complexity',\n",
       "       'Retroposon', 'Satellite', 'Simple_repeat', 'rRNA', 'snRNA', 'scRNA',\n",
       "       'srpRNA', 'tRNA', 'RC', 'L1_s', 'L2_s', 'MIR_s', 'Alu_s', 'Satellite_s',\n",
       "       'component_size', 'intra_degree', 'iner_degree', 'self_loops',\n",
       "       'edges_double', 'edges_tandem', 'edges_ident_mean_0',\n",
       "       'edges_ident_mean_1', 'CG_frac_0', 'CG_frac_1', 'CG_frac_in_0',\n",
       "       'CG_frac_in_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ML_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f018cfb7-c448-4c32-87f4-bb8e22dbdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML_output.to_csv(\"files/Duplicated_Regions_Final_10MB.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe6319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
